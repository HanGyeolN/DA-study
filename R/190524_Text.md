R Notebook
================

``` r
library(stringr)
library(tm)
```

    ## Loading required package: NLP

### 공백 처리하기

``` r
#각각 " ", "  ", "\t"으로 구분된다.
mytext<-c("software environment",
  "software  environment",
  "software\tenvironment")
mytext
```

    ## [1] "software environment"  "software  environment" "software\tenvironment"

``` r
mt<-str_split(mytext," ")
mt
```

    ## [[1]]
    ## [1] "software"    "environment"
    ## 
    ## [[2]]
    ## [1] "software"    ""            "environment"
    ## 
    ## [[3]]
    ## [1] "software\tenvironment"

``` r
# sapply(입력: 리스트, 출력: 벡터)
# lapply(I: list, O: list)
lapply(mt, str_length)
```

    ## [[1]]
    ## [1]  8 11
    ## 
    ## [[2]]
    ## [1]  8  0 11
    ## 
    ## [[3]]
    ## [1] 20

``` r
sapply(mt, str_length)
```

    ## [[1]]
    ## [1]  8 11
    ## 
    ## [[2]]
    ## [1]  8  0 11
    ## 
    ## [[3]]
    ## [1] 20

``` r
# "hi         hello" -> "hi hello"
str_replace_all(mytext,"[[:space:]]{1,}", " ")->mt2

 

sapply(mt2, length)
```

    ## software environment software environment software environment 
    ##                    1                    1                    1

``` r
sapply(mt2, str_length)
```

    ## software environment software environment software environment 
    ##                   20                   20                   20

### extract\_all에 boundary 옵션으로 특수문자 처리

``` r
mytext<-"The 45th President of the United States, Donald Trump, states that he knows how to play trump with the former president"

str_split(mytext, " ") 
```

    ## [[1]]
    ##  [1] "The"       "45th"      "President" "of"        "the"      
    ##  [6] "United"    "States,"   "Donald"    "Trump,"    "states"   
    ## [11] "that"      "he"        "knows"     "how"       "to"       
    ## [16] "play"      "trump"     "with"      "the"       "former"   
    ## [21] "president"

``` r
#,가 안없어짐

# 고급함수
str_extract_all(mytext, boundary("word"))
```

    ## [[1]]
    ##  [1] "The"       "45th"      "President" "of"        "the"      
    ##  [6] "United"    "States"    "Donald"    "Trump"     "states"   
    ## [11] "that"      "he"        "knows"     "how"       "to"       
    ## [16] "play"      "trump"     "with"      "the"       "former"   
    ## [21] "president"

``` r
#,가 없어짐

myword<-unlist(str_extract_all(mytext, boundary("word")))
myword
```

    ##  [1] "The"       "45th"      "President" "of"        "the"      
    ##  [6] "United"    "States"    "Donald"    "Trump"     "states"   
    ## [11] "that"      "he"        "knows"     "how"       "to"       
    ## [16] "play"      "trump"     "with"      "the"       "former"   
    ## [21] "president"

``` r
myword<-str_replace(myword,"Trump", "Trump_unique_")
myword<-str_replace(myword,"States", "States_unique_")
tolower(myword)
```

    ##  [1] "the"            "45th"           "president"      "of"            
    ##  [5] "the"            "united"         "states_unique_" "donald"        
    ##  [9] "trump_unique_"  "states"         "that"           "he"            
    ## [13] "knows"          "how"            "to"             "play"          
    ## [17] "trump"          "with"           "the"            "former"        
    ## [21] "president"

### 숫자 처리하기

``` r
# 구분 될 필요가 있는 숫자

mytext<-c("He is one of statisticians agreeing that R is the No. 1 statistical software.","He is one of statisticians agreeing that R is the No. one statistical software.")
str_split(mytext," ")
```

    ## [[1]]
    ##  [1] "He"            "is"            "one"           "of"           
    ##  [5] "statisticians" "agreeing"      "that"          "R"            
    ##  [9] "is"            "the"           "No."           "1"            
    ## [13] "statistical"   "software."    
    ## 
    ## [[2]]
    ##  [1] "He"            "is"            "one"           "of"           
    ##  [5] "statisticians" "agreeing"      "that"          "R"            
    ##  [9] "is"            "the"           "No."           "one"          
    ## [13] "statistical"   "software."

``` r
str_replace_all(mytext, "[[:digit:]]{1,}[[:space:]]{1,}", "") -> mytext2
str_split(mytext2, " ")->mytext2
mytext2
```

    ## [[1]]
    ##  [1] "He"            "is"            "one"           "of"           
    ##  [5] "statisticians" "agreeing"      "that"          "R"            
    ##  [9] "is"            "the"           "No."           "statistical"  
    ## [13] "software."    
    ## 
    ## [[2]]
    ##  [1] "He"            "is"            "one"           "of"           
    ##  [5] "statisticians" "agreeing"      "that"          "R"            
    ##  [9] "is"            "the"           "No."           "one"          
    ## [13] "statistical"   "software."

``` r
str_c(mytext2[[1]], collapse = " ")
```

    ## [1] "He is one of statisticians agreeing that R is the No. statistical software."

``` r
str_c(mytext2[[2]], collapse = " ")
```

    ## [1] "He is one of statisticians agreeing that R is the No. one statistical software."

``` r
# 숫자 처리 
mytext3<-str_replace_all(mytext, "[[:digit:]]{1,}", "_number_")
mytext3
```

    ## [1] "He is one of statisticians agreeing that R is the No. _number_ statistical software."
    ## [2] "He is one of statisticians agreeing that R is the No. one statistical software."

``` r
mytext3<-str_split(mytext3, " ")
mytext3
```

    ## [[1]]
    ##  [1] "He"            "is"            "one"           "of"           
    ##  [5] "statisticians" "agreeing"      "that"          "R"            
    ##  [9] "is"            "the"           "No."           "_number_"     
    ## [13] "statistical"   "software."    
    ## 
    ## [[2]]
    ##  [1] "He"            "is"            "one"           "of"           
    ##  [5] "statisticians" "agreeing"      "that"          "R"            
    ##  [9] "is"            "the"           "No."           "one"          
    ## [13] "statistical"   "software."

### 특수문자, 불용어 처리하기

``` r
# 구분 될 필요가 있는 특수문자 
mytext<-"Baek et al. (2014) argued that the state of default-setting is critical for people to protect their own personal privacy on the Internet." # Baek et al = Baek 외에 여러명

#str_split(mytext, "\\.")

# "성씨 다음 et al.이 오고, 이어서(년도)형식
# => "_reference_"로 일괄 치환
# 하이픈 기호 

# 1. 하이픈
mytext2<-str_replace_all(mytext, "-", " ")
mytext2<-str_replace_all(mytext2,"[[:upper:]]{1}[[:alpha:]]{1,}[[:space:]]{1}(et al\\.)[[:space:]]{1}\\([[:digit:]]{4}\\)","_reference_")
mytext2
```

    ## [1] "_reference_ argued that the state of default setting is critical for people to protect their own personal privacy on the Internet."

``` r
# 2. . 공백 제거
mytext2<-str_replace_all(mytext2,"\\.[[:space:]]{0,}","")
mytext2
```

    ## [1] "_reference_ argued that the state of default setting is critical for people to protect their own personal privacy on the Internet"

``` r
# 3. 불용어 직접 등록, 제거
mystopwords<- "(\\ba )|(\\ban )|(\\bthe )"

mytext<-c("she is an actor", "She is the actor")
str_replace_all(mytext, mystopwords,"")
```

    ## [1] "she is actor" "She is actor"

``` r
# 4. 정의되어있는 불용어 사용하기
# stopwords("en") # 짧은 불용어
# stopwords("SMART") # 긴 불용어

# 어근 동일화 처리
# 시제 고려 -> 동일화
# ~s ~es -> 동일화
```

### 불용어 처리 함수

``` r
mystemmer.func<-function(mytext){
  mytext<-str_replace_all(mytext, "(\\bam )|(\\bare )|(\\bas )|(\\bwas )|(\\bwere )|(\\bbe)", "be ")
print(mytext)
}

test<-c("i am a boy. You are a boy. He mitght be a boy")

mystemmer.func(test)
```

    ## [1] "i be a boy. You be a boy. He mitght be  a boy"

## n-gram

``` r
# n-gram : 1-gram(의미없음)
#          2-gram(bi-gram), 3-gram(tri-gram)
# n번 연이어 등장하는 단어들의 연결
# 등장배경 : 문장에 대해 이해하기 위해서
# 단어 분리시 문장에 대한 의미가 어려워진다.
# n gram + bayes => 문맥파악

"The United States comprises fifty states. In the United States, each state has its own laws. However, federal law overrides state law in the United States." -> mytext

# extract로 split보다 깔끔하게 분리 가능하다. 
str_extract_all(mytext, boundary(type="word"))
```

    ## [[1]]
    ##  [1] "The"       "United"    "States"    "comprises" "fifty"    
    ##  [6] "states"    "In"        "the"       "United"    "States"   
    ## [11] "each"      "state"     "has"       "its"       "own"      
    ## [16] "laws"      "However"   "federal"   "law"       "overrides"
    ## [21] "state"     "law"       "in"        "the"       "United"   
    ## [26] "States"

``` r
str_extract_all(mytext, boundary(type="word")) -> myword

# 등장한 단어의 빈도수
table(myword)
```

    ## myword
    ## comprises      each   federal     fifty       has   However        in 
    ##         1         1         1         1         1         1         1 
    ##        In       its       law      laws overrides       own     state 
    ##         1         1         2         1         1         1         2 
    ##    states    States       the       The    United 
    ##         1         3         2         1         3

``` r
# 모든 단어의 갯수
sum(table(myword))
```

    ## [1] 26

``` r
# 서로 다른 단어의 개수
length(table(myword))
```

    ## [1] 19

``` r
# 위처럼 나누면 united의 states와 동사 states 구분이 안된다.
# 따라서 고유명사는 전처리 할 필요가 있다.

str_replace_all(mytext, "\\bUnited States", "United_States")
```

    ## [1] "The United_States comprises fifty states. In the United_States, each state has its own laws. However, federal law overrides state law in the United_States."

``` r
str_replace_all(mytext, "\\bUnited States", "United_States")->mytext.2gram
str_extract_all(mytext.2gram, boundary(type="word"))
```

    ## [[1]]
    ##  [1] "The"           "United_States" "comprises"     "fifty"        
    ##  [5] "states"        "In"            "the"           "United_States"
    ##  [9] "each"          "state"         "has"           "its"          
    ## [13] "own"           "laws"          "However"       "federal"      
    ## [17] "law"           "overrides"     "state"         "law"          
    ## [21] "in"            "the"           "United_States"

#### Corpus 구성

``` r
# library(tm)
my.text.location<-"C:/rwork/Data/papers/papers/"
my.text.location
```

    ## [1] "C:/rwork/Data/papers/papers/"

``` r
# tm(text mining) 패키지 이용

# txt파일을 모두 합쳐서 Corpus로 만든다.
VCorpus(DirSource(my.text.location))
```

    ## <<VCorpus>>
    ## Metadata:  corpus specific: 0, document level (indexed): 0
    ## Content:  documents: 24

``` r
VCorpus(DirSource(my.text.location))->mypaper

# Corpus 정보 확인
class(mypaper)
```

    ## [1] "VCorpus" "Corpus"

``` r
summary(mypaper)
```

    ##            Length Class             Mode
    ## p2009a.txt 2      PlainTextDocument list
    ## p2009b.txt 2      PlainTextDocument list
    ## p2010a.txt 2      PlainTextDocument list
    ## p2010b.txt 2      PlainTextDocument list
    ## p2010c.txt 2      PlainTextDocument list
    ## p2011a.txt 2      PlainTextDocument list
    ## p2011b.txt 2      PlainTextDocument list
    ## p2012a.txt 2      PlainTextDocument list
    ## p2012b.txt 2      PlainTextDocument list
    ## p2013a.txt 2      PlainTextDocument list
    ## p2014a.txt 2      PlainTextDocument list
    ## p2014b.txt 2      PlainTextDocument list
    ## p2014c.txt 2      PlainTextDocument list
    ## p2014d.txt 2      PlainTextDocument list
    ## p2014e.txt 2      PlainTextDocument list
    ## p2014f.txt 2      PlainTextDocument list
    ## p2014g.txt 2      PlainTextDocument list
    ## p2014h.txt 2      PlainTextDocument list
    ## p2014i.txt 2      PlainTextDocument list
    ## p2014k.txt 2      PlainTextDocument list
    ## p2015a.txt 2      PlainTextDocument list
    ## p2015b.txt 2      PlainTextDocument list
    ## p2015c.txt 2      PlainTextDocument list
    ## p2015d.txt 2      PlainTextDocument list

``` r
mypaper[[1]]$meta
```

    ##   author       : character(0)
    ##   datetimestamp: 2019-05-24 05:02:02
    ##   description  : character(0)
    ##   heading      : character(0)
    ##   id           : p2009a.txt
    ##   language     : en
    ##   origin       : character(0)

``` r
mypaper[[2]]$meta
```

    ##   author       : character(0)
    ##   datetimestamp: 2019-05-24 05:02:02
    ##   description  : character(0)
    ##   heading      : character(0)
    ##   id           : p2009b.txt
    ##   language     : en
    ##   origin       : character(0)
