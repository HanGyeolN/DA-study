{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"네이버 영화평점 naive bayes.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qWnrfJPq-vSK","colab_type":"text"},"source":["## 분류기"]},{"cell_type":"code","metadata":{"id":"1MjpjaRPxERU","colab_type":"code","outputId":"f2ed5c26-e141-4308-8eb6-d5e3a748d1b5","executionInfo":{"status":"ok","timestamp":1565683390986,"user_tz":-540,"elapsed":661,"user":{"displayName":"나한결","photoUrl":"","userId":"00133112916651542324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":114,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MDzcYiIx8zhX","colab_type":"code","outputId":"caf8293f-7bed-4e0c-c2b8-e900bb58a220","executionInfo":{"status":"ok","timestamp":1565683394373,"user_tz":-540,"elapsed":3777,"user":{"displayName":"나한결","photoUrl":"","userId":"00133112916651542324"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["!pip install konlpy"],"execution_count":115,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Requirement already satisfied: JPype1>=0.5.7 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EGLNvyaEw-G0","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import konlpy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"geVJPorjxCPG","colab_type":"code","colab":{}},"source":["train = pd.read_csv(\"/content/drive/My Drive/data/ratings_train.txt\", sep=\"\\t\") \n","test = pd.read_csv(\"/content/drive/My Drive/data/ratings_test.txt\", sep=\"\\t\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHvjUHP2xasv","colab_type":"code","colab":{}},"source":["class BayesianFilter:\n","  def __init__(self): # 객체 내에서 전역변수\n","    self.words = set() # set 자료구조 : 중복불가\n","    self.word_dict = {} \n","    self.category_dict = {}\n","    self.likelihood_dict = {}\n","\n","  def split(self, text):\n","    '''\n","    split 함수는 문장에서 단어들을 분리하고 구두점, 조사, 어미를 \\n\n","    제거한다.\n","    =========================================\n","    parameter \\n\n","    text : (str) 문자열\n","    '''\n","    okt = konlpy.tag.Okt()\n","    malist = okt.pos(text, norm=True, stem=True)\n","    # print(malist)\n","\n","    ## 조사 어미 구두점 제거\n","    result = []\n","    \n","    for word in malist:\n","      if word[1] not in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n","        result.append(word[0])\n","    \n","    return result\n","\n","  def inc_word(self, word, category):\n","    '''\n","    inc_word 함수는 카테고리별로 단어가 등장한 횟수를 계산한다.\\n\n","    word_dict = { \\n\n","      '광고' : {'파격':1, '세일':1, ...}\\n\n","      '중요' : {'일정':1, '확인':1, ...}\\n\n","    }\\n\n","    word_dict는 객체 내에서 global하기 때문에 자유롭게 fit 훈련이 가능하다.\n","    ==========================================\n","    parameter \\n\n","    word : (str) 단어 1개\n","    category : (str) 그 문장의 카테고리\n","    \n","    '''\n","    if category not in self.word_dict: \n","      self.word_dict[category] = {}\n","    \n","    # 초기화\n","    for cate in self.word_dict:\n","      if word not in self.word_dict[cate]:\n","        # 0이 되는걸 방지하기 위해 1로 초기화 \n","        self.word_dict[cate][word] = 1\n","    \n","    # +1\n","    self.word_dict[category][word] += 1 \n","    self.words.add(word) # 알아서 중복이 제거된다.\n","    \n","  def inc_category(self, category):\n","    if category not in self.category_dict:\n","      self.category_dict[category] = 0\n","    self.category_dict[category] += 1\n","\n","  def arr_sum(self, arr):\n","    res = 0\n","    for v in arr:\n","      res += v\n","    \n","    return res\n","\n","  def arr_mul(self, arr):\n","    res = 1\n","    for v in arr:\n","      res *= v\n","\n","    return res\n","\n","  def likelihood(self):\n","    '''\n","    우도표 제작\n","    '''\n","    # 카테고리별 전체 단어수 계산\n","    word_sum = {}\n","    for cate in self.word_dict.keys():\n","      word_counts = self.word_dict[cate].values()\n","      word_sum[cate] = self.arr_sum(word_counts)\n","    \n","    # 카테고리, 단어별 우도 계산\n","    for cate in self.word_dict.keys():\n","      self.likelihood_dict[cate] = {}\n","\n","      for word in self.word_dict[cate]:\n","        self.likelihood_dict[cate][word] = self.word_dict[cate][word] / word_sum[cate]\n","    \n","    return self.likelihood_dict\n","\n","  def predict(self, text):\n","    '''\n","    예측\n","    '''\n","    \n","    # P(label) = n(label) / n(labels)\n","\n","    # n(labels)\n","    # 전체 카테고리 갯수\n","    sums = self.arr_sum(self.category_dict.values())\n","    \n","    # P(label)\n","    # 전체에 대한 각 카테고리 확률 계산\n","    p_cate = {}\n","    for cate in self.category_dict.keys():\n","      p_cate[cate] = self.category_dict[cate]/sums\n","    \n","\n","    # 입력 문자열 해체\n","    words = self.split(text)   \n","\n","    # 단어들이 나왔을때 각 카테고리에 들어갈 확률 계산\n","    pred_dict = {}\n","\n","    for cate in self.word_dict:\n","\n","      word_vals = []\n","      for word in words:\n","        # 학습되지 않은 단어라면 스킵\n","        if word not in self.likelihood_dict[cate]:\n","          continue\n","\n","        val = self.likelihood_dict[cate][word]\n","        word_vals.append(val)\n","      \n","      # 우도 x p(라벨)\n","      hf = self.arr_mul(word_vals) * p_cate[cate]\n","      \n","      pred_dict[cate] = hf\n","\n","      prediction = list(pred_dict.keys())[np.argmax(list(pred_dict.values()))]      \n","    \n","    return prediction, pred_dict\n","\n","  def fit(self, text, category):\n","    '''\n","    fit 함수는 Bayesian Filter를 훈련시킨다.\n","    ========================================\n","    parameter \\n\n","    text : (str) 문자열 \\n\n","    category : (str) 중요인지 광고인지 label\n","    '''\n","    word_list = self.split(text)\n","    # print(word_list)\n","\n","    for word in word_list:\n","      self.inc_word(word, category)    \n","    self.inc_category(category)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"otjbrcLPxZ9A","colab_type":"code","colab":{}},"source":["bf = BayesianFilter()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JM8Y_uNX9Ch9","colab_type":"code","colab":{}},"source":["train = train.fillna('')\n","\n","train_texts = train['document'].values\n","train_labels = train['label'].values\n","\n","train_zip = zip(train_texts, train_labels)\n","total_train = len(train_texts)\n","\n","# test\n","test = test.fillna('')\n","\n","test_texts = test['document'].values\n","test_labels = test['label'].values\n","\n","test_zip = zip(test_texts, test_labels)\n","total_test = len(test_texts)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GJ77oYzA-p-S","colab_type":"text"},"source":["## 학습"]},{"cell_type":"code","metadata":{"id":"LqaY6V0mJTz_","colab_type":"code","colab":{}},"source":["batch = 150000\n","\n","for i in range(batch):\n","  text, category = next(train_zip)\n","  bf.fit(text, category)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tIkKMrdf-n-b","colab_type":"text"},"source":["## 우도 계산"]},{"cell_type":"code","metadata":{"id":"T_GeBZU79NUU","colab_type":"code","outputId":"6761b3d5-e841-4f61-e693-47f68d6141d3","executionInfo":{"status":"ok","timestamp":1565682130986,"user_tz":-540,"elapsed":579,"user":{"displayName":"나한결","photoUrl":"","userId":"00133112916651542324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["bf.likelihood()\n","print(\"ok\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ok\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EzM6zfutVzpF","colab_type":"code","outputId":"3913b5a7-93ff-454e-e4f0-7311c31b8bb7","executionInfo":{"status":"ok","timestamp":1565682132618,"user_tz":-540,"elapsed":585,"user":{"displayName":"나한결","photoUrl":"","userId":"00133112916651542324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["bf.predict(test_texts[4])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0, {0: 7.440320452175902e-54, 1: 3.4465374221996403e-56})"]},"metadata":{"tags":[]},"execution_count":110}]},{"cell_type":"markdown","metadata":{"id":"slsXFrks-hyd","colab_type":"text"},"source":["## 테스트 정확도 계산\n"]},{"cell_type":"code","metadata":{"id":"WFn3LjDUwjbu","colab_type":"code","outputId":"4e0da607-1953-48bc-bcc6-afe4ddabfe6f","executionInfo":{"status":"ok","timestamp":1565682384927,"user_tz":-540,"elapsed":250619,"user":{"displayName":"나한결","photoUrl":"","userId":"00133112916651542324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_size = 50000\n","pred = []\n","\n","# 예측 리스트 생성\n","for i in range(test_size):\n","  pred.append(bf.predict(test_texts[i]))\n","\n","# 정답 갯수 확인\n","correct = 0\n","for i in range(test_size):\n","  if pred[i][0] == test_labels[i]:\n","    correct += 1\n","\n","# 정확도\n","print(\"정확도:\", (correct/test_size)*100)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["정확도: 84.19200000000001\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sFWkmiTj8c6K","colab_type":"text"},"source":["## 테스트"]},{"cell_type":"code","metadata":{"id":"Fg0gla3F8eM5","colab_type":"code","outputId":"9438e6ff-a896-4c4b-9b37-b4961d117382","executionInfo":{"status":"ok","timestamp":1565682544435,"user_tz":-540,"elapsed":577,"user":{"displayName":"나한결","photoUrl":"","userId":"00133112916651542324"}},"colab":{"base_uri":"https://localhost:8080/","height":250}},"source":["for i in [0,2,29,1999,20289,35000]:\n","  print(test_texts[i])\n","  print(bf.predict(test_texts[i]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["굳 ㅋ\n","(1, {0: 2.2221964680313306e-08, 1: 3.9795510356476893e-07})\n","뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n","(0, {0: 1.5355518641514873e-36, 1: 3.469608763707977e-37})\n","지금까지 본 영화중 마음이 가장 따뜻해지는 영화.\n","(1, {0: 9.274601414432237e-23, 1: 1.0210002826109496e-19})\n","초등학교 6학년. 우리들의 일그러진 영웅을 읽고 주제에 대해 글을 써오라는 숙제가 주어졌었고 난 이 소설의 깊이를 전혀 이해 못한채 줄거리만 배껴 써내기 바빴던 기억이 난다. 당연히 이해 못할수 밖에.\n","(0, {0: 1.8229302592091564e-119, 1: 1.4600798697905398e-119})\n","성우가 좀 그랬지만 10점\n","(0, {0: 5.4186010734480904e-15, 1: 8.388040500904165e-16})\n","감성팔이 10자끝?\n","(1, {0: 1.1184093053552316e-17, 1: 1.4400381061252936e-17})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hm0JOsNKALr_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"55730cc1-9bf1-47b1-888d-e506508a3a4d","executionInfo":{"status":"ok","timestamp":1565683414591,"user_tz":-540,"elapsed":614,"user":{"displayName":"나한결","photoUrl":"","userId":"00133112916651542324"}}},"source":["test['label'].value_counts()"],"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    25173\n","0    24827\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":118}]}]}